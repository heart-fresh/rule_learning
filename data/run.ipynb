{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "list = [2325,3274,3821,4972,6624,6750,8202,8683,9773,10178,10251,11090,11897]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tiwen(df, indexs): #提问，多类\n",
    "    question_words = [\"how\", \"what\", \"why\", \"where\", \"when\", \"who\", \"whom\", \"which\", \"whose\"]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(question_words) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return happen_list[0]\n",
    "    else:\n",
    "        return \"More\"\n",
    "\n",
    "def find_fanwen(df, indexs): #反问，3类\n",
    "    negatives_with_pronouns = [  \n",
    "    \"Wasn't it\",\"Aren't you\",\"Didn't you\",\"Wouldn't you\",\"Don't you\",\"Isn't that\",\"Isn't it\",\"Wasn't he\",\"Wasn't she\",\n",
    "    \"Wasn't they\",\"Weren't we\",\"Weren't you\",\"Haven't you\",\"Hasn't he\",\"Hasn't she\",\"Hadn't you\",\"Hadn't they\",\n",
    "    \"Wasn't there\",\"Wasn't here\",\n",
    "    \"Don't they\",\"Doesn't he\",\"Doesn't she\",\"Can't you\",\"Couldn't you\",\"Shouldn't you\",\"Wouldn't it\",\"Won't you\",\n",
    "    \"Needn't we\",\"Needn't they\",\"Mustn't you\",\"Daren't we\",\"Daren't they\",\"Was not it\",\"Are not you\",\"Did not you\",\n",
    "    \"Would not you\",\"Do not you\",\"Is not that\",\"Is not it\",\"Was not he\",\"Was not she\",\"Was not they\",\"Were not we\",\n",
    "    \"Were not you\",\"Have not you\",\"Has not he\",\"Has not she\",\"Had not you\",\"Had not they\",\"Do not they\",\"Does not he\",\n",
    "    \"Does not she\",\"Can not you\",\"Could not you\",\"Should not you\",\"Would not it\",\"Will not you\",\"Need not we\",\n",
    "    \"Need not they\",\"Must not you\",\"Dare not we\",\"Dare not they\"\"You sure?\",\"You are sure?\",\"You're sure?\",\"Sure about that?\",\n",
    "    \"Are you certain?\",\"You certain?\",\"Do you really think so?\",\"You really think that?\",\n",
    "    \"You positive?\",\"You sure about that?\",\"Confident about that?\",\"Are you convinced?\",\"You convinced?\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            for word in negatives_with_pronouns:\n",
    "                text = str(df.Text[i])\n",
    "                pattern_start = rf'\\b{re.escape(word)}\\b(?![^(]*\\))'\n",
    "                if re.findall(pattern_start, text, re.IGNORECASE):\n",
    "                    happen_list.extend([word])\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_gif(df, indexs): #gif，2类\n",
    "    happen_list = []\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b\\w+\\.gif\\b(?![^(]*\\))', text)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return 'Exist'\n",
    "    \n",
    "def find_thoughts(df, indexs): #心理，2类\n",
    "    happen_list = []\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\([^()]*\\)', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if bool(happen_list):\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return 'Null'\n",
    "\n",
    "def find_yinwen(df, indexs): # 引问，3类\n",
    "    positives_with_pronouns = [ \n",
    "    \"Was it\", \"Are you\", \"Did you\", \"Would you\",\"Do you\", \"Is that\", \"Is it\", \"Was he\", \"Was she\",\n",
    "    \"Were they\", \"Were we\", \"Were you\", \"Have you\",\"Has he\", \"Has she\", \"Had you\", \"Had they\",\n",
    "    \"Do they\", \"Does he\", \"Does she\", \"Can you\",\"Could you\", \"Should you\", \"Would it\", \"Will you\",\n",
    "    \"Need we\", \"Need they\", \"Must you\", \"Dare we\",\"Dare they\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(positives_with_pronouns) + r')\\b(?![^(]*\\))', text , re.IGNORECASE)\n",
    "            happen_list = happen_list + word + re.findall(r\",correct[.!?]\", text, re.IGNORECASE)\n",
    "            \n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "\n",
    "def find_zhiyi(df, indexs): #质疑，3类\n",
    "    questioning_terms = [ \n",
    "    \"confused\", \"strange\", \"vague\", \"ridiculous\",\n",
    "    \"odd\", \"demand an explanation\", \"problem\", \"trap\",\n",
    "    \"blind spots\", \"useless\", \"unaware\", \"yet\", \"stinks\"\n",
    "    \"doubt\", \"challenge\", \"question\", \"query\",\n",
    "    \"dispute\", \"skeptical\", \"raise concerns\", \"ask\",\n",
    "    \"interrogate\", \"probe\", \"examine\", \"doubtful\",\n",
    "    \"call into question\", \"contest\", \"reconsider\", \"scrutinize\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(questioning_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_xujia(df, indexs): #虚假，2类\n",
    "    false_terms = [ \n",
    "    \"false\", \"fake\", \"fictitious\", \"bogus\", \"fraudulent\",\n",
    "    \"spurious\", \"counterfeit\", \"phony\", \"sham\", \"artificial\",\n",
    "    \"unreal\", \"impostor\", \"fabricated\", \"deceptive\", \"illusory\",\n",
    "    \"pretend\", \"pseudo\",\"fabrication\", \"lie\", \"lying \",\"unlikely\",\n",
    "    \"no way\",\"impossible\", \"wrong\", \"none\", \"no\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(false_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "\n",
    "def find_fouding(df, indexs): #否定，2类\n",
    "    negatives = [ \n",
    "    \"am not\", \"is not\", \"isn't\", \"are not\", \"aren't\", \"was not\", \"wasn't\", \"were not\", \"weren't\",\n",
    "    \"have not\", \"haven't\", \"has not\", \"hasn't\", \"had not\", \"hadn't\",\n",
    "    \"do not\", \"don't\", \"does not\", \"doesn't\", \"did not\", \"didn't\",\n",
    "    \"will not\", \"won't\", \"would not\", \"wouldn't\", \"shall not\", \"shan't\", \n",
    "    \"should not\", \"shouldn't\", \"can not\", \"cannot\", \"can't\", \"could not\", \"couldn't\", \n",
    "    \"may not\", \"might not\", \"mightn't\", \"must not\", \"mustn't\", \"ought not to\", \"oughtn't to\",\n",
    "    \"need not\", \"needn't\", \"dare not\", \"daren't\", \"holding out against\",\n",
    "    'objection', \"oppose\", \"disagree\", \"object\",\"resist\", \"protest\",  \"contest\",\"Hold it right\",\"disagreement\"\n",
    "    \"refute\", \"counter\", \"dispute\", \"debate\",\"object to\",  \"take issue with\", \"hold out against\",\n",
    "    \"opposed\", \"disagreed\", \"objected\", \"resisted\", \"protested\", \"contested\",\n",
    "    \"refuted\", \"countered\", \"disputed\", \"debated\", \"objected to\", \"took issue with\",\n",
    "    \"held out against\",\"opposing\", \"disagreeing\", \"objecting\", \"resisting\", \"protesting\", \"contesting\",\n",
    "    \"refuting\", \"countering\", \"disputing\", \"debating\", \"objecting to\", \"taking issue with\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            for word in negatives:\n",
    "                text = str(df.Text[i])\n",
    "                pattern_middle = rf'\\b{re.escape(word)}\\b(?![^(]*\\))'\n",
    "                if re.findall(pattern_middle, text):\n",
    "                    happen_list.extend([word])\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_yinguo(df, indexs): #因果，2类\n",
    "    causality = ['because','becaused','reason','so','reasons' ] \n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(causality) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "    \n",
    "def find_tingdun(df, indexs): #停顿，2类\n",
    "    pause = ['wait','moment','second','minute',\"moments\", \"seconds\", \"minutes\",\n",
    "            \"waited\", \"waited\", \"waiting\"] \n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(pause) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "    \n",
    "def find_judge(df): # judge\n",
    "    happen_list = []\n",
    "    for i in df.index:\n",
    "        if df.Name[i] == 'Judge':\n",
    "            return 'Exist'\n",
    "    return 'Null'\n",
    "\n",
    "def find_maodun(df, indexs): #矛盾，2类\n",
    "    contr_terms=['contradict', 'contradiction', 'conflict', 'confliction',\"contradicted\", \n",
    "                \"contradicted\", \"contradicting\", \"conflicted\", \"conflicted\", \"conflicting\", \n",
    "                \"contradictions\", \"conflicts\", \"conflictions\"] \n",
    "    happen_list = []\n",
    "\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(contr_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "\n",
    "def find_all(sample): # 函数总调用\n",
    "    middle_index = sample[(sample['Name'] == 'Phoenix') & (sample['Text'] == 'Objection.gif')].index\n",
    "    middle = middle_index.tolist()[0]\n",
    "    end = sample.index[-1]\n",
    "    temp = []\n",
    "    func_pre = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    func_aft = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    \n",
    "    result = [find_judge(sample)]\n",
    "    for func in func_pre:\n",
    "        result.append(func(sample, range(middle)))\n",
    "    for func in func_aft:\n",
    "        result.append(func(sample, range(middle+1, end+1)))\n",
    "    return result\n",
    "\n",
    "def select_numbers(data, num_to_select, min_gap): #随机采样负样本\n",
    "    selected = []\n",
    "    current_number = random.choice(data)\n",
    "    selected.append(current_number)\n",
    "    remaining_data = set(data) - {current_number}\n",
    "    while len(selected) < num_to_select:\n",
    "        valid_candidates = [num for num in remaining_data if abs(num - current_number) > min_gap]\n",
    "        if not valid_candidates:\n",
    "            raise ValueError(\"无法找到符合条件的更多数字\")\n",
    "        current_number = random.choice(valid_candidates)\n",
    "        selected.append(current_number)\n",
    "        remaining_data.remove(current_number)\n",
    "    return selected\n",
    "\n",
    "def e_find_all(e_sample): # 函数总调用（负样本）\n",
    "    middle = len(e_sample)//2\n",
    "    end = e_sample.index[-1]\n",
    "    temp = []\n",
    "    func_pre = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    func_aft = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    \n",
    "    result = [find_judge(e_sample)]\n",
    "    for func in func_pre:\n",
    "        result.append(func(e_sample, range(middle)))\n",
    "    for func in func_aft:\n",
    "        result.append(func(e_sample, range(middle+1, end+1)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\\\Users\\\\11326\\\\Desktop\\\\rule_leaning_new\\\\rule_learning\\\\rule_learning\\\\data.csv')\n",
    "indices = df[(df['Name'] == 'Phoenix') & (df['Text'] == 'Objection.gif')].index\n",
    "columns = [  #22个特征\n",
    "    'judge',\n",
    "    'pre_question', 'pre_rhetorical_question', 'pre_gif',\n",
    "    'pre_thoughts', 'pre_assess', 'pre_doubt',\n",
    "    'pre_negation', 'pre_pauses', 'pre_causation',\n",
    "    'pre_falsity', 'pre_conflict',\n",
    "    'aft_question', 'aft_rhetorical_question', 'aft_gif',\n",
    "    'aft_thoughts', 'aft_assess', 'aft_doubt',\n",
    "    'aft_negation', 'aft_pauses', 'aft_causation', \n",
    "    'aft_falsity', 'aft_conflict'\n",
    "]\n",
    "row_num = len(indices)  #行数\n",
    "col_num = len(columns)  #列数\n",
    "data = [[f'Row_{i+1}_Col_{j+1}' for j in range(col_num)] for i in range(row_num )] #初始值\n",
    "df_g = pd.DataFrame(data, columns=columns, index=indices) #生成数据表"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx in list:\n",
    "    start_idx = max(0, idx - 10)  # 确保开始索引不小于0\n",
    "    end_idx = min(len(df), idx + 11)  # 确保结束索引不超过 DataFrame 长度\n",
    "    adjacent_rows = df.iloc[start_idx:end_idx][['Name', 'Text']]  # 只选择 Name 和 Text 两列\n",
    "    sample = adjacent_rows.reset_index(drop=True) # 索引重新从0开始\n",
    "    df_g.loc[idx] = e_find_all(sample) #数据框赋值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_g.loc[list].to_csv('different.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pre_question      What\n",
      "pre_gif          Exist\n",
      "pre_thoughts     Exist\n",
      "pre_assess       Exist\n",
      "aft_question     where\n",
      "aft_causation    Exist\n",
      "Name: 2325, dtype: object\n",
      "judge                      Exist\n",
      "aft_question                More\n",
      "aft_rhetorical_question    Exist\n",
      "aft_thoughts               Exist\n",
      "aft_assess                  More\n",
      "aft_negation               Exist\n",
      "Name: 3274, dtype: object\n",
      "judge           Exist\n",
      "pre_question     More\n",
      "pre_gif         Exist\n",
      "pre_negation    Exist\n",
      "aft_question     More\n",
      "Name: 3821, dtype: object\n",
      "judge                      Exist\n",
      "pre_gif                    Exist\n",
      "pre_thoughts               Exist\n",
      "aft_rhetorical_question    Exist\n",
      "aft_negation               Exist\n",
      "Name: 4972, dtype: object\n",
      "judge           Exist\n",
      "pre_thoughts    Exist\n",
      "pre_doubt       Exist\n",
      "pre_negation    Exist\n",
      "aft_question      who\n",
      "aft_thoughts    Exist\n",
      "aft_doubt        More\n",
      "aft_pauses      Exist\n",
      "Name: 6624, dtype: object\n",
      "judge           Exist\n",
      "pre_thoughts    Exist\n",
      "pre_falsity     Exist\n",
      "aft_thoughts    Exist\n",
      "aft_negation     More\n",
      "Name: 6750, dtype: object\n",
      "judge           Exist\n",
      "pre_question     What\n",
      "pre_thoughts    Exist\n",
      "pre_falsity     Exist\n",
      "aft_question     More\n",
      "aft_gif         Exist\n",
      "aft_thoughts    Exist\n",
      "aft_negation    Exist\n",
      "aft_falsity     Exist\n",
      "Name: 8202, dtype: object\n",
      "judge           Exist\n",
      "pre_question      why\n",
      "pre_gif         Exist\n",
      "pre_thoughts    Exist\n",
      "aft_question      How\n",
      "aft_thoughts    Exist\n",
      "aft_negation    Exist\n",
      "Name: 8683, dtype: object\n",
      "judge                      Exist\n",
      "pre_question                when\n",
      "pre_rhetorical_question    Exist\n",
      "pre_thoughts               Exist\n",
      "pre_doubt                  Exist\n",
      "pre_negation               Exist\n",
      "pre_causation              Exist\n",
      "aft_question                When\n",
      "aft_pauses                 Exist\n",
      "Name: 9773, dtype: object\n",
      "judge                      Exist\n",
      "pre_rhetorical_question    Exist\n",
      "pre_thoughts               Exist\n",
      "pre_negation               Exist\n",
      "aft_question                 why\n",
      "aft_thoughts               Exist\n",
      "aft_assess                 Exist\n",
      "aft_causation              Exist\n",
      "Name: 10178, dtype: object\n",
      "judge           Exist\n",
      "pre_thoughts    Exist\n",
      "aft_question     when\n",
      "aft_gif         Exist\n",
      "aft_thoughts    Exist\n",
      "aft_conflict    Exist\n",
      "Name: 10251, dtype: object\n",
      "judge           Exist\n",
      "pre_thoughts    Exist\n",
      "pre_falsity     Exist\n",
      "aft_thoughts    Exist\n",
      "aft_negation     More\n",
      "Name: 11090, dtype: object\n",
      "judge           Exist\n",
      "pre_gif         Exist\n",
      "pre_thoughts    Exist\n",
      "aft_thoughts    Exist\n",
      "Name: 11897, dtype: object\n"
     ]
    }
   ],
   "source": [
    "dff = df_g.loc[list]\n",
    "for index in list:\n",
    "    row = dff.loc[index]\n",
    "    non_a_elements = row[row != 'Null']\n",
    "    print(non_a_elements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ema</td>\n",
       "      <td>Way to go, Detective! I didn't know you had a ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Gumshoe</td>\n",
       "      <td>Yeah, well... ha ha! You see... Mr. Wright her...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Huh? Huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Gumshoe</td>\n",
       "      <td>What, you think I could afford that with my sa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Huh? Huh? Huh?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Ema</td>\n",
       "      <td>Thank you, Mr. Wright! You're the best!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>... (Why is it... I suddenly feel like I want ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Gumshoe</td>\n",
       "      <td>Since we're all here, why don't we all go toge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Ema</td>\n",
       "      <td>Yeah, that's a great idea! Come on, guys! Let'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Objection.gif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name                                               Text\n",
       "0   Phoenix                                               Huh?\n",
       "1       Ema  Way to go, Detective! I didn't know you had a ...\n",
       "2   Gumshoe  Yeah, well... ha ha! You see... Mr. Wright her...\n",
       "3   Phoenix                                          Huh? Huh?\n",
       "4   Gumshoe  What, you think I could afford that with my sa...\n",
       "5   Phoenix                                     Huh? Huh? Huh?\n",
       "6       Ema            Thank you, Mr. Wright! You're the best!\n",
       "7   Phoenix  ... (Why is it... I suddenly feel like I want ...\n",
       "8   Gumshoe  Since we're all here, why don't we all go toge...\n",
       "9       Ema  Yeah, that's a great idea! Come on, guys! Let'...\n",
       "10  Phoenix                                      Objection.gif"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "indices = df[(df['Name'] == 'Phoenix') & (df['Text'] == 'Objection.gif')].index\n",
    "for idx in indices:\n",
    "    start_idx = max(0, idx - 10)  # 确保开始索引不小于0\n",
    "    end_idx = min(len(df), idx + 11)  # 确保结束索引不超过 DataFrame 长度\n",
    "    adjacent_rows = df.iloc[start_idx:end_idx][['Name', 'Text']]  # 只选择 Name 和 Text 两列\n",
    "    sample = adjacent_rows.reset_index(drop=True)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "middle_index = sample[(sample['Name'] == 'Phoenix') & (sample['Text'] == 'Objection.gif')].index\n",
    "middle = middle_index.tolist()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "middle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tiwen(df, indexs): #提问，多类\n",
    "    question_words = [\"how\", \"what\", \"why\", \"where\", \"when\", \"who\", \"whom\", \"which\", \"whose\"]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(question_words) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return happen_list[0]\n",
    "    else:\n",
    "        return \"More\"\n",
    "\n",
    "def find_fanwen(df, indexs): #反问，3类\n",
    "    negatives_with_pronouns = [  \n",
    "    \"Wasn't it\",\"Aren't you\",\"Didn't you\",\"Wouldn't you\",\"Don't you\",\"Isn't that\",\"Isn't it\",\"Wasn't he\",\"Wasn't she\",\n",
    "    \"Wasn't they\",\"Weren't we\",\"Weren't you\",\"Haven't you\",\"Hasn't he\",\"Hasn't she\",\"Hadn't you\",\"Hadn't they\",\n",
    "    \"Wasn't there\",\"Wasn't here\",\n",
    "    \"Don't they\",\"Doesn't he\",\"Doesn't she\",\"Can't you\",\"Couldn't you\",\"Shouldn't you\",\"Wouldn't it\",\"Won't you\",\n",
    "    \"Needn't we\",\"Needn't they\",\"Mustn't you\",\"Daren't we\",\"Daren't they\",\"Was not it\",\"Are not you\",\"Did not you\",\n",
    "    \"Would not you\",\"Do not you\",\"Is not that\",\"Is not it\",\"Was not he\",\"Was not she\",\"Was not they\",\"Were not we\",\n",
    "    \"Were not you\",\"Have not you\",\"Has not he\",\"Has not she\",\"Had not you\",\"Had not they\",\"Do not they\",\"Does not he\",\n",
    "    \"Does not she\",\"Can not you\",\"Could not you\",\"Should not you\",\"Would not it\",\"Will not you\",\"Need not we\",\n",
    "    \"Need not they\",\"Must not you\",\"Dare not we\",\"Dare not they\"\"You sure?\",\"You are sure?\",\"You're sure?\",\"Sure about that?\",\n",
    "    \"Are you certain?\",\"You certain?\",\"Do you really think so?\",\"You really think that?\",\n",
    "    \"You positive?\",\"You sure about that?\",\"Confident about that?\",\"Are you convinced?\",\"You convinced?\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            for word in negatives_with_pronouns:\n",
    "                text = str(df.Text[i])\n",
    "                pattern_start = rf'\\b{re.escape(word)}\\b(?![^(]*\\))'\n",
    "                if re.findall(pattern_start, text, re.IGNORECASE):\n",
    "                    happen_list.extend([word])\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_gif(df, indexs): #gif，2类\n",
    "    happen_list = []\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b\\w+\\.gif\\b(?![^(]*\\))', text)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return 'Exist'\n",
    "    \n",
    "def find_thoughts(df, indexs): #心理，2类\n",
    "    happen_list = []\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\([^()]*\\)', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if bool(happen_list):\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return 'Null'\n",
    "\n",
    "def find_yinwen(df, indexs): # 引问，3类\n",
    "    positives_with_pronouns = [ \n",
    "    \"Was it\", \"Are you\", \"Did you\", \"Would you\",\"Do you\", \"Is that\", \"Is it\", \"Was he\", \"Was she\",\n",
    "    \"Were they\", \"Were we\", \"Were you\", \"Have you\",\"Has he\", \"Has she\", \"Had you\", \"Had they\",\n",
    "    \"Do they\", \"Does he\", \"Does she\", \"Can you\",\"Could you\", \"Should you\", \"Would it\", \"Will you\",\n",
    "    \"Need we\", \"Need they\", \"Must you\", \"Dare we\",\"Dare they\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(positives_with_pronouns) + r')\\b(?![^(]*\\))', text , re.IGNORECASE)\n",
    "            happen_list = happen_list + word + re.findall(r\",correct[.!?]\", text, re.IGNORECASE)\n",
    "            \n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "\n",
    "def find_zhiyi(df, indexs): #质疑，3类\n",
    "    questioning_terms = [ \n",
    "    \"confused\", \"strange\", \"vague\", \"ridiculous\",\n",
    "    \"odd\", \"demand an explanation\", \"problem\", \"trap\",\n",
    "    \"blind spots\", \"useless\", \"unaware\", \"yet\", \"stinks\"\n",
    "    \"doubt\", \"challenge\", \"question\", \"query\",\n",
    "    \"dispute\", \"skeptical\", \"raise concerns\", \"ask\",\n",
    "    \"interrogate\", \"probe\", \"examine\", \"doubtful\",\n",
    "    \"call into question\", \"contest\", \"reconsider\", \"scrutinize\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(questioning_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_xujia(df, indexs): #虚假，2类\n",
    "    false_terms = [ \n",
    "    \"false\", \"fake\", \"fictitious\", \"bogus\", \"fraudulent\",\n",
    "    \"spurious\", \"counterfeit\", \"phony\", \"sham\", \"artificial\",\n",
    "    \"unreal\", \"impostor\", \"fabricated\", \"deceptive\", \"illusory\",\n",
    "    \"pretend\", \"pseudo\",\"fabrication\", \"lie\", \"lying \",\"unlikely\",\n",
    "    \"no way\",\"impossible\", \"wrong\", \"none\", \"no\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(false_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "\n",
    "def find_fouding(df, indexs): #否定，2类\n",
    "    negatives = [ \n",
    "    \"am not\", \"is not\", \"isn't\", \"are not\", \"aren't\", \"was not\", \"wasn't\", \"were not\", \"weren't\",\n",
    "    \"have not\", \"haven't\", \"has not\", \"hasn't\", \"had not\", \"hadn't\",\n",
    "    \"do not\", \"don't\", \"does not\", \"doesn't\", \"did not\", \"didn't\",\n",
    "    \"will not\", \"won't\", \"would not\", \"wouldn't\", \"shall not\", \"shan't\", \n",
    "    \"should not\", \"shouldn't\", \"can not\", \"cannot\", \"can't\", \"could not\", \"couldn't\", \n",
    "    \"may not\", \"might not\", \"mightn't\", \"must not\", \"mustn't\", \"ought not to\", \"oughtn't to\",\n",
    "    \"need not\", \"needn't\", \"dare not\", \"daren't\", \"holding out against\",\n",
    "    'objection', \"oppose\", \"disagree\", \"object\",\"resist\", \"protest\",  \"contest\",\"Hold it right\",\"disagreement\"\n",
    "    \"refute\", \"counter\", \"dispute\", \"debate\",\"object to\",  \"take issue with\", \"hold out against\",\n",
    "    \"opposed\", \"disagreed\", \"objected\", \"resisted\", \"protested\", \"contested\",\n",
    "    \"refuted\", \"countered\", \"disputed\", \"debated\", \"objected to\", \"took issue with\",\n",
    "    \"held out against\",\"opposing\", \"disagreeing\", \"objecting\", \"resisting\", \"protesting\", \"contesting\",\n",
    "    \"refuting\", \"countering\", \"disputing\", \"debating\", \"objecting to\", \"taking issue with\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            for word in negatives:\n",
    "                text = str(df.Text[i])\n",
    "                pattern_middle = rf'\\b{re.escape(word)}\\b(?![^(]*\\))'\n",
    "                if re.findall(pattern_middle, text):\n",
    "                    happen_list.extend([word])\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_yinguo(df, indexs): #因果，2类\n",
    "    causality = ['because','becaused','reason','so','reasons' ] \n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(causality) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "    \n",
    "def find_tingdun(df, indexs): #停顿，2类\n",
    "    pause = ['wait','moment','second','minute',\"moments\", \"seconds\", \"minutes\",\n",
    "            \"waited\", \"waited\", \"waiting\"] \n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(pause) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "    \n",
    "def find_judge(df): # judge\n",
    "    happen_list = []\n",
    "    for i in df.index:\n",
    "        if df.Name[i] == 'Judge':\n",
    "            return 'Exist'\n",
    "    return 'Null'\n",
    "\n",
    "def find_maodun(df, indexs): #矛盾，2类\n",
    "    contr_terms=['contradict', 'contradiction', 'conflict', 'confliction',\"contradicted\", \n",
    "                \"contradicted\", \"contradicting\", \"conflicted\", \"conflicted\", \"conflicting\", \n",
    "                \"contradictions\", \"conflicts\", \"conflictions\"] \n",
    "    happen_list = []\n",
    "\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(contr_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_all(sample): # 函数总调用\n",
    "    middle_index = sample[(sample['Name'] == 'Phoenix') & (sample['Text'] == 'Objection.gif')].index\n",
    "    middle = middle_index.tolist()[0]\n",
    "    end = sample.index[-1]\n",
    "    temp = []\n",
    "    func_pre = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    func_aft = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    \n",
    "    result = [find_judge(sample)]\n",
    "    for func in func_pre:\n",
    "        result.append(func(sample, range(middle)))\n",
    "    for func in func_aft:\n",
    "        result.append(func(sample, range(middle+1, end+1)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('C:\\\\Users\\\\v-xinszhang\\\\Desktop\\\\rule_learning\\\\rule_learning\\\\data.csv')\n",
    "indices = df[(df['Name'] == 'Phoenix') & (df['Text'] == 'Objection.gif')].index\n",
    "columns = [\n",
    "    'judge',\n",
    "    'pre_question', 'pre_rhetorical_question', 'pre_gif',\n",
    "    'pre_thoughts', 'pre_assess', 'pre_doubt',\n",
    "    'pre_negation', 'pre_pauses', 'pre_causation',\n",
    "    'pre_falsity', 'pre_conflict',\n",
    "    'aft_question', 'aft_rhetorical_question', 'aft_gif',\n",
    "    'aft_thoughts', 'aft_assess', 'aft_doubt',\n",
    "    'aft_negation', 'aft_pauses', 'aft_causation', \n",
    "    'aft_falsity', 'aft_conflict'\n",
    "]\n",
    "row_num = len(indices)\n",
    "col_num = len(columns)\n",
    "data = [[f'Row_{i+1}_Col_{j+1}' for j in range(col_num)] for i in range(row_num )]\n",
    "df_g = pd.DataFrame(data, columns=columns, index=indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "exist_idx = set()\n",
    "for idx in indices:\n",
    "    start_idx = max(0, idx - 10)  # 确保开始索引不小于0\n",
    "    end_idx = min(len(df), idx + 11)  # 确保结束索引不超过 DataFrame 长度\n",
    "    exist_idx.update(range(start_idx, end_idx))\n",
    "    adjacent_rows = df.iloc[start_idx:end_idx][['Name', 'Text']]  # 只选择 Name 和 Text 两列\n",
    "    sample = adjacent_rows.reset_index(drop=True) # 索引重新从0开始\n",
    "    df_g.loc[idx] = find_all(sample) #数据框赋值\n",
    "\n",
    "df_g['class'] = 'p'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_Phoenix = df[(df['Name'] == 'Phoenix')].index\n",
    "no_idx = []\n",
    "for i in index_Phoenix:\n",
    "    if i not in exist_idx and min(len(df), i+11) not in exist_idx and max(0, i-10) not in exist_idx:\n",
    "        no_idx.append(i)\n",
    "no_idx = no_idx[10:-10]  #剔除边界值"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def select_numbers(data, num_to_select, min_gap):\n",
    "    selected = []\n",
    "    current_number = random.choice(data)\n",
    "    selected.append(current_number)\n",
    "    remaining_data = set(data) - {current_number}\n",
    "    while len(selected) < num_to_select:\n",
    "        valid_candidates = [num for num in remaining_data if abs(num - current_number) > min_gap]\n",
    "        if not valid_candidates:\n",
    "            raise ValueError(\"无法找到符合条件的更多数字\")\n",
    "        current_number = random.choice(valid_candidates)\n",
    "        selected.append(current_number)\n",
    "        remaining_data.remove(current_number)\n",
    "    return selected\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_gap = 50\n",
    "selected_index = select_numbers(no_idx, row_num, min_gap)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "def e_find_all(e_sample): # 函数总调用\n",
    "    middle = len(e_sample)//2\n",
    "    end = sample.index[-1]\n",
    "    temp = []\n",
    "    func_pre = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    func_aft = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    \n",
    "    result = [find_judge(sample)]\n",
    "    for func in func_pre:\n",
    "        result.append(func(sample, range(middle)))\n",
    "    for func in func_aft:\n",
    "        result.append(func(sample, range(middle+1, end+1)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [],
   "source": [
    "for e_idx in selected_index:\n",
    "    e_adjacent_rows = df.iloc[e_idx-10 : e_idx+11][['Name', 'Text']]  # 只选择 Name 和 Text 两列\n",
    "    e_sample = e_adjacent_rows.reset_index(drop=True) # 索引重新从0开始\n",
    "    new_feature = e_find_all(e_sample) \n",
    "    new_feature.append('e')\n",
    "    df_g.loc[e_idx] = pd.Series(new_feature, index=df_g.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>judge</th>\n",
       "      <th>pre_question</th>\n",
       "      <th>pre_rhetorical_question</th>\n",
       "      <th>pre_gif</th>\n",
       "      <th>pre_thoughts</th>\n",
       "      <th>pre_assess</th>\n",
       "      <th>pre_doubt</th>\n",
       "      <th>pre_negation</th>\n",
       "      <th>pre_pauses</th>\n",
       "      <th>pre_causation</th>\n",
       "      <th>...</th>\n",
       "      <th>aft_gif</th>\n",
       "      <th>aft_thoughts</th>\n",
       "      <th>aft_assess</th>\n",
       "      <th>aft_doubt</th>\n",
       "      <th>aft_negation</th>\n",
       "      <th>aft_pauses</th>\n",
       "      <th>aft_causation</th>\n",
       "      <th>aft_falsity</th>\n",
       "      <th>aft_conflict</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Exist</td>\n",
       "      <td>More</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Exist</td>\n",
       "      <td>More</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>More</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Exist</td>\n",
       "      <td>Why</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>More</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Exist</td>\n",
       "      <td>Where</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5680</th>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6031</th>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1088</th>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Exist</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>...</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>Null</td>\n",
       "      <td>e</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>164 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      judge pre_question pre_rhetorical_question pre_gif pre_thoughts  \\\n",
       "163   Exist         More                    Null   Exist        Exist   \n",
       "210   Exist         Null                    Null   Exist         Null   \n",
       "237   Exist          Why                   Exist   Exist        Exist   \n",
       "720   Exist         Null                   Exist    Null        Exist   \n",
       "851   Exist        Where                    Null   Exist        Exist   \n",
       "...     ...          ...                     ...     ...          ...   \n",
       "1053   Null         Null                    Null    Null        Exist   \n",
       "5680   Null         Null                    Null    Null        Exist   \n",
       "6031   Null         Null                    Null    Null        Exist   \n",
       "1088   Null         Null                    Null    Null        Exist   \n",
       "31     Null         Null                    Null    Null        Exist   \n",
       "\n",
       "     pre_assess pre_doubt pre_negation pre_pauses pre_causation  ... aft_gif  \\\n",
       "163        More      Null         Null       Null          Null  ...    Null   \n",
       "210       Exist      Null         Null       Null          Null  ...    Null   \n",
       "237        Null      Null        Exist       Null          Null  ...    Null   \n",
       "720        Null     Exist         Null       Null          Null  ...    Null   \n",
       "851        Null      Null         Null       Null          Null  ...    Null   \n",
       "...         ...       ...          ...        ...           ...  ...     ...   \n",
       "1053       Null      Null         Null       Null          Null  ...    Null   \n",
       "5680       Null      Null         Null       Null          Null  ...    Null   \n",
       "6031       Null      Null         Null       Null          Null  ...    Null   \n",
       "1088       Null      Null         Null       Null          Null  ...    Null   \n",
       "31         Null      Null         Null       Null          Null  ...    Null   \n",
       "\n",
       "     aft_thoughts aft_assess aft_doubt aft_negation aft_pauses aft_causation  \\\n",
       "163          Null      Exist      Null         Null       Null          Null   \n",
       "210          Null       Null      Null         More       Null          Null   \n",
       "237          Null       Null      More        Exist      Exist          Null   \n",
       "720          Null       Null      Null        Exist       Null          Null   \n",
       "851          Null      Exist      Null         Null       Null          Null   \n",
       "...           ...        ...       ...          ...        ...           ...   \n",
       "1053         Null       Null      Null         Null       Null          Null   \n",
       "5680         Null       Null      Null         Null       Null          Null   \n",
       "6031         Null       Null      Null         Null       Null          Null   \n",
       "1088         Null       Null      Null         Null       Null          Null   \n",
       "31           Null       Null      Null         Null       Null          Null   \n",
       "\n",
       "     aft_falsity aft_conflict class  \n",
       "163        Exist         Null     p  \n",
       "210         Null         Null     p  \n",
       "237         Null        Exist     p  \n",
       "720        Exist         Null     p  \n",
       "851        Exist         Null     p  \n",
       "...          ...          ...   ...  \n",
       "1053        Null         Null     e  \n",
       "5680        Null         Null     e  \n",
       "6031        Null         Null     e  \n",
       "1088        Null         Null     e  \n",
       "31          Null         Null     e  \n",
       "\n",
       "[164 rows x 24 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df_g, test_size=.33, random_state=42)\n",
    "import wittgenstein as lw\n",
    "clf = lw.RIPPER()\n",
    "clf.fit(train, class_feat='class', pos_class='p')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[judge=Exist] V\n",
      "[pre_question=What] V\n",
      "[pre_question=More]]\n"
     ]
    }
   ],
   "source": [
    "clf.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 1.0 recall: 1.0 conds: 3\n"
     ]
    }
   ],
   "source": [
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "from sklearn.metrics import precision_score, recall_score\n",
    "precision = clf.score(X_test, y_test, precision_score)\n",
    "recall = clf.score(X_test, y_test, recall_score)\n",
    "cond_count = clf.ruleset_.count_conds()\n",
    "print(f'precision: {precision} recall: {recall} conds: {cond_count}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index([  163,   210,   237,   720,   851,   863,  1499,  1571,  1582,  1614,\n",
       "        1740,  2223,  2325,  2373,  3175,  3233,  3306,  3759,  3972,  4824,\n",
       "        4939,  4998,  5039,  5102,  5711,  5793,  5801,  5922,  5959,  5997,\n",
       "        6624,  6750,  6819,  6884,  7001,  7193,  7961,  7974,  7992,  8012,\n",
       "        8096,  8179,  8202,  8220,  8232,  8255,  8368,  8431,  8447,  8592,\n",
       "        9698,  9773,  9808,  9943,  9998, 10178, 10251, 10286, 10318, 10710,\n",
       "       11090, 11197, 11271, 11288, 11293, 11296, 11391, 11407, 11417, 11502,\n",
       "       11636, 11683, 11689, 11789, 11852, 12020, 12085, 12094, 12102, 12317,\n",
       "       12339, 12533],\n",
       "      dtype='int64')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# 导入CSV文件并转换为DataFrame\n",
    "df = pd.read_csv('C:\\\\Users\\\\v-xinszhang\\\\Desktop\\\\rule_learning\\\\rule_learning\\\\data.csv')\n",
    "indices = df[(df['Name'] == 'Phoenix') & (df['Text'] == 'Objection.gif')].index\n",
    "# 定义列名\n",
    "columns = [\n",
    "    'judge',\n",
    "    'pre_question', 'pre_rhetorical_question', 'pre_gif',\n",
    "    'pre_thoughts', 'pre_assess', 'pre_doubt',\n",
    "    'pre_negation', 'pre_pauses', 'pre_causation',\n",
    "    'pre_falsity', 'pre_conflict',\n",
    "    'aft_question', 'aft_rhetorical_question', 'aft_gif',\n",
    "    'aft_thoughts', 'aft_assess', 'aft_doubt',\n",
    "    'aft_negation', 'aft_pauses', 'aft_causation', \n",
    "    'aft_falsity', 'aft_conflict'\n",
    "]\n",
    "row_num = len(indices)\n",
    "col_num = len(columns)\n",
    "\n",
    "data = [[f'Row_{i+1}_Col_{j+1}' for j in range(col_num)] for i in range(row_num )]\n",
    "df_g = pd.DataFrame(data, columns=columns, index=indices)\n",
    "\n",
    "df_g.index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pre_question</th>\n",
       "      <th>pre_rhetorical_question</th>\n",
       "      <th>pre_gif</th>\n",
       "      <th>pre_thoughts</th>\n",
       "      <th>pre_assess</th>\n",
       "      <th>pre_doubt</th>\n",
       "      <th>pre_negation</th>\n",
       "      <th>pre_pauses</th>\n",
       "      <th>pre_causation</th>\n",
       "      <th>judge</th>\n",
       "      <th>...</th>\n",
       "      <th>aft_rhetorical_question</th>\n",
       "      <th>aft_gif</th>\n",
       "      <th>aft_thoughts</th>\n",
       "      <th>aft_assess</th>\n",
       "      <th>aft_doubt</th>\n",
       "      <th>aft_negation</th>\n",
       "      <th>aft_pauses</th>\n",
       "      <th>aft_causation</th>\n",
       "      <th>aft_falsity</th>\n",
       "      <th>aft_conflict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>sd</td>\n",
       "      <td>Row_1_Col_2</td>\n",
       "      <td>Row_1_Col_3</td>\n",
       "      <td>Row_1_Col_4</td>\n",
       "      <td>Row_1_Col_5</td>\n",
       "      <td>Row_1_Col_6</td>\n",
       "      <td>Row_1_Col_7</td>\n",
       "      <td>Row_1_Col_8</td>\n",
       "      <td>Row_1_Col_9</td>\n",
       "      <td>Row_1_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_1_Col_14</td>\n",
       "      <td>Row_1_Col_15</td>\n",
       "      <td>Row_1_Col_16</td>\n",
       "      <td>Row_1_Col_17</td>\n",
       "      <td>Row_1_Col_18</td>\n",
       "      <td>Row_1_Col_19</td>\n",
       "      <td>Row_1_Col_20</td>\n",
       "      <td>Row_1_Col_21</td>\n",
       "      <td>Row_1_Col_22</td>\n",
       "      <td>Row_1_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Row_2_Col_1</td>\n",
       "      <td>Row_2_Col_2</td>\n",
       "      <td>Row_2_Col_3</td>\n",
       "      <td>Row_2_Col_4</td>\n",
       "      <td>Row_2_Col_5</td>\n",
       "      <td>Row_2_Col_6</td>\n",
       "      <td>Row_2_Col_7</td>\n",
       "      <td>Row_2_Col_8</td>\n",
       "      <td>Row_2_Col_9</td>\n",
       "      <td>Row_2_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_2_Col_14</td>\n",
       "      <td>Row_2_Col_15</td>\n",
       "      <td>Row_2_Col_16</td>\n",
       "      <td>Row_2_Col_17</td>\n",
       "      <td>Row_2_Col_18</td>\n",
       "      <td>Row_2_Col_19</td>\n",
       "      <td>Row_2_Col_20</td>\n",
       "      <td>Row_2_Col_21</td>\n",
       "      <td>Row_2_Col_22</td>\n",
       "      <td>Row_2_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Row_3_Col_1</td>\n",
       "      <td>Row_3_Col_2</td>\n",
       "      <td>Row_3_Col_3</td>\n",
       "      <td>Row_3_Col_4</td>\n",
       "      <td>Row_3_Col_5</td>\n",
       "      <td>Row_3_Col_6</td>\n",
       "      <td>Row_3_Col_7</td>\n",
       "      <td>Row_3_Col_8</td>\n",
       "      <td>Row_3_Col_9</td>\n",
       "      <td>Row_3_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_3_Col_14</td>\n",
       "      <td>Row_3_Col_15</td>\n",
       "      <td>Row_3_Col_16</td>\n",
       "      <td>Row_3_Col_17</td>\n",
       "      <td>Row_3_Col_18</td>\n",
       "      <td>Row_3_Col_19</td>\n",
       "      <td>Row_3_Col_20</td>\n",
       "      <td>Row_3_Col_21</td>\n",
       "      <td>Row_3_Col_22</td>\n",
       "      <td>Row_3_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>720</th>\n",
       "      <td>Row_4_Col_1</td>\n",
       "      <td>Row_4_Col_2</td>\n",
       "      <td>Row_4_Col_3</td>\n",
       "      <td>Row_4_Col_4</td>\n",
       "      <td>Row_4_Col_5</td>\n",
       "      <td>Row_4_Col_6</td>\n",
       "      <td>Row_4_Col_7</td>\n",
       "      <td>Row_4_Col_8</td>\n",
       "      <td>Row_4_Col_9</td>\n",
       "      <td>Row_4_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_4_Col_14</td>\n",
       "      <td>Row_4_Col_15</td>\n",
       "      <td>Row_4_Col_16</td>\n",
       "      <td>Row_4_Col_17</td>\n",
       "      <td>Row_4_Col_18</td>\n",
       "      <td>Row_4_Col_19</td>\n",
       "      <td>Row_4_Col_20</td>\n",
       "      <td>Row_4_Col_21</td>\n",
       "      <td>Row_4_Col_22</td>\n",
       "      <td>Row_4_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Row_5_Col_1</td>\n",
       "      <td>Row_5_Col_2</td>\n",
       "      <td>Row_5_Col_3</td>\n",
       "      <td>Row_5_Col_4</td>\n",
       "      <td>Row_5_Col_5</td>\n",
       "      <td>Row_5_Col_6</td>\n",
       "      <td>Row_5_Col_7</td>\n",
       "      <td>Row_5_Col_8</td>\n",
       "      <td>Row_5_Col_9</td>\n",
       "      <td>Row_5_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_5_Col_14</td>\n",
       "      <td>Row_5_Col_15</td>\n",
       "      <td>Row_5_Col_16</td>\n",
       "      <td>Row_5_Col_17</td>\n",
       "      <td>Row_5_Col_18</td>\n",
       "      <td>Row_5_Col_19</td>\n",
       "      <td>Row_5_Col_20</td>\n",
       "      <td>Row_5_Col_21</td>\n",
       "      <td>Row_5_Col_22</td>\n",
       "      <td>Row_5_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12094</th>\n",
       "      <td>Row_78_Col_1</td>\n",
       "      <td>Row_78_Col_2</td>\n",
       "      <td>Row_78_Col_3</td>\n",
       "      <td>Row_78_Col_4</td>\n",
       "      <td>Row_78_Col_5</td>\n",
       "      <td>Row_78_Col_6</td>\n",
       "      <td>Row_78_Col_7</td>\n",
       "      <td>Row_78_Col_8</td>\n",
       "      <td>Row_78_Col_9</td>\n",
       "      <td>Row_78_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_78_Col_14</td>\n",
       "      <td>Row_78_Col_15</td>\n",
       "      <td>Row_78_Col_16</td>\n",
       "      <td>Row_78_Col_17</td>\n",
       "      <td>Row_78_Col_18</td>\n",
       "      <td>Row_78_Col_19</td>\n",
       "      <td>Row_78_Col_20</td>\n",
       "      <td>Row_78_Col_21</td>\n",
       "      <td>Row_78_Col_22</td>\n",
       "      <td>Row_78_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12102</th>\n",
       "      <td>Row_79_Col_1</td>\n",
       "      <td>Row_79_Col_2</td>\n",
       "      <td>Row_79_Col_3</td>\n",
       "      <td>Row_79_Col_4</td>\n",
       "      <td>Row_79_Col_5</td>\n",
       "      <td>Row_79_Col_6</td>\n",
       "      <td>Row_79_Col_7</td>\n",
       "      <td>Row_79_Col_8</td>\n",
       "      <td>Row_79_Col_9</td>\n",
       "      <td>Row_79_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_79_Col_14</td>\n",
       "      <td>Row_79_Col_15</td>\n",
       "      <td>Row_79_Col_16</td>\n",
       "      <td>Row_79_Col_17</td>\n",
       "      <td>Row_79_Col_18</td>\n",
       "      <td>Row_79_Col_19</td>\n",
       "      <td>Row_79_Col_20</td>\n",
       "      <td>Row_79_Col_21</td>\n",
       "      <td>Row_79_Col_22</td>\n",
       "      <td>Row_79_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12317</th>\n",
       "      <td>Row_80_Col_1</td>\n",
       "      <td>Row_80_Col_2</td>\n",
       "      <td>Row_80_Col_3</td>\n",
       "      <td>Row_80_Col_4</td>\n",
       "      <td>Row_80_Col_5</td>\n",
       "      <td>Row_80_Col_6</td>\n",
       "      <td>Row_80_Col_7</td>\n",
       "      <td>Row_80_Col_8</td>\n",
       "      <td>Row_80_Col_9</td>\n",
       "      <td>Row_80_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_80_Col_14</td>\n",
       "      <td>Row_80_Col_15</td>\n",
       "      <td>Row_80_Col_16</td>\n",
       "      <td>Row_80_Col_17</td>\n",
       "      <td>Row_80_Col_18</td>\n",
       "      <td>Row_80_Col_19</td>\n",
       "      <td>Row_80_Col_20</td>\n",
       "      <td>Row_80_Col_21</td>\n",
       "      <td>Row_80_Col_22</td>\n",
       "      <td>Row_80_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12339</th>\n",
       "      <td>Row_81_Col_1</td>\n",
       "      <td>Row_81_Col_2</td>\n",
       "      <td>Row_81_Col_3</td>\n",
       "      <td>Row_81_Col_4</td>\n",
       "      <td>Row_81_Col_5</td>\n",
       "      <td>Row_81_Col_6</td>\n",
       "      <td>Row_81_Col_7</td>\n",
       "      <td>Row_81_Col_8</td>\n",
       "      <td>Row_81_Col_9</td>\n",
       "      <td>Row_81_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_81_Col_14</td>\n",
       "      <td>Row_81_Col_15</td>\n",
       "      <td>Row_81_Col_16</td>\n",
       "      <td>Row_81_Col_17</td>\n",
       "      <td>Row_81_Col_18</td>\n",
       "      <td>Row_81_Col_19</td>\n",
       "      <td>Row_81_Col_20</td>\n",
       "      <td>Row_81_Col_21</td>\n",
       "      <td>Row_81_Col_22</td>\n",
       "      <td>Row_81_Col_23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12533</th>\n",
       "      <td>Row_82_Col_1</td>\n",
       "      <td>Row_82_Col_2</td>\n",
       "      <td>Row_82_Col_3</td>\n",
       "      <td>Row_82_Col_4</td>\n",
       "      <td>Row_82_Col_5</td>\n",
       "      <td>Row_82_Col_6</td>\n",
       "      <td>Row_82_Col_7</td>\n",
       "      <td>Row_82_Col_8</td>\n",
       "      <td>Row_82_Col_9</td>\n",
       "      <td>Row_82_Col_10</td>\n",
       "      <td>...</td>\n",
       "      <td>Row_82_Col_14</td>\n",
       "      <td>Row_82_Col_15</td>\n",
       "      <td>Row_82_Col_16</td>\n",
       "      <td>Row_82_Col_17</td>\n",
       "      <td>Row_82_Col_18</td>\n",
       "      <td>Row_82_Col_19</td>\n",
       "      <td>Row_82_Col_20</td>\n",
       "      <td>Row_82_Col_21</td>\n",
       "      <td>Row_82_Col_22</td>\n",
       "      <td>Row_82_Col_23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>82 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       pre_question pre_rhetorical_question       pre_gif  pre_thoughts  \\\n",
       "163              sd             Row_1_Col_2   Row_1_Col_3   Row_1_Col_4   \n",
       "210     Row_2_Col_1             Row_2_Col_2   Row_2_Col_3   Row_2_Col_4   \n",
       "237     Row_3_Col_1             Row_3_Col_2   Row_3_Col_3   Row_3_Col_4   \n",
       "720     Row_4_Col_1             Row_4_Col_2   Row_4_Col_3   Row_4_Col_4   \n",
       "851     Row_5_Col_1             Row_5_Col_2   Row_5_Col_3   Row_5_Col_4   \n",
       "...             ...                     ...           ...           ...   \n",
       "12094  Row_78_Col_1            Row_78_Col_2  Row_78_Col_3  Row_78_Col_4   \n",
       "12102  Row_79_Col_1            Row_79_Col_2  Row_79_Col_3  Row_79_Col_4   \n",
       "12317  Row_80_Col_1            Row_80_Col_2  Row_80_Col_3  Row_80_Col_4   \n",
       "12339  Row_81_Col_1            Row_81_Col_2  Row_81_Col_3  Row_81_Col_4   \n",
       "12533  Row_82_Col_1            Row_82_Col_2  Row_82_Col_3  Row_82_Col_4   \n",
       "\n",
       "         pre_assess     pre_doubt  pre_negation    pre_pauses pre_causation  \\\n",
       "163     Row_1_Col_5   Row_1_Col_6   Row_1_Col_7   Row_1_Col_8   Row_1_Col_9   \n",
       "210     Row_2_Col_5   Row_2_Col_6   Row_2_Col_7   Row_2_Col_8   Row_2_Col_9   \n",
       "237     Row_3_Col_5   Row_3_Col_6   Row_3_Col_7   Row_3_Col_8   Row_3_Col_9   \n",
       "720     Row_4_Col_5   Row_4_Col_6   Row_4_Col_7   Row_4_Col_8   Row_4_Col_9   \n",
       "851     Row_5_Col_5   Row_5_Col_6   Row_5_Col_7   Row_5_Col_8   Row_5_Col_9   \n",
       "...             ...           ...           ...           ...           ...   \n",
       "12094  Row_78_Col_5  Row_78_Col_6  Row_78_Col_7  Row_78_Col_8  Row_78_Col_9   \n",
       "12102  Row_79_Col_5  Row_79_Col_6  Row_79_Col_7  Row_79_Col_8  Row_79_Col_9   \n",
       "12317  Row_80_Col_5  Row_80_Col_6  Row_80_Col_7  Row_80_Col_8  Row_80_Col_9   \n",
       "12339  Row_81_Col_5  Row_81_Col_6  Row_81_Col_7  Row_81_Col_8  Row_81_Col_9   \n",
       "12533  Row_82_Col_5  Row_82_Col_6  Row_82_Col_7  Row_82_Col_8  Row_82_Col_9   \n",
       "\n",
       "               judge  ... aft_rhetorical_question        aft_gif  \\\n",
       "163     Row_1_Col_10  ...            Row_1_Col_14   Row_1_Col_15   \n",
       "210     Row_2_Col_10  ...            Row_2_Col_14   Row_2_Col_15   \n",
       "237     Row_3_Col_10  ...            Row_3_Col_14   Row_3_Col_15   \n",
       "720     Row_4_Col_10  ...            Row_4_Col_14   Row_4_Col_15   \n",
       "851     Row_5_Col_10  ...            Row_5_Col_14   Row_5_Col_15   \n",
       "...              ...  ...                     ...            ...   \n",
       "12094  Row_78_Col_10  ...           Row_78_Col_14  Row_78_Col_15   \n",
       "12102  Row_79_Col_10  ...           Row_79_Col_14  Row_79_Col_15   \n",
       "12317  Row_80_Col_10  ...           Row_80_Col_14  Row_80_Col_15   \n",
       "12339  Row_81_Col_10  ...           Row_81_Col_14  Row_81_Col_15   \n",
       "12533  Row_82_Col_10  ...           Row_82_Col_14  Row_82_Col_15   \n",
       "\n",
       "        aft_thoughts     aft_assess      aft_doubt   aft_negation  \\\n",
       "163     Row_1_Col_16   Row_1_Col_17   Row_1_Col_18   Row_1_Col_19   \n",
       "210     Row_2_Col_16   Row_2_Col_17   Row_2_Col_18   Row_2_Col_19   \n",
       "237     Row_3_Col_16   Row_3_Col_17   Row_3_Col_18   Row_3_Col_19   \n",
       "720     Row_4_Col_16   Row_4_Col_17   Row_4_Col_18   Row_4_Col_19   \n",
       "851     Row_5_Col_16   Row_5_Col_17   Row_5_Col_18   Row_5_Col_19   \n",
       "...              ...            ...            ...            ...   \n",
       "12094  Row_78_Col_16  Row_78_Col_17  Row_78_Col_18  Row_78_Col_19   \n",
       "12102  Row_79_Col_16  Row_79_Col_17  Row_79_Col_18  Row_79_Col_19   \n",
       "12317  Row_80_Col_16  Row_80_Col_17  Row_80_Col_18  Row_80_Col_19   \n",
       "12339  Row_81_Col_16  Row_81_Col_17  Row_81_Col_18  Row_81_Col_19   \n",
       "12533  Row_82_Col_16  Row_82_Col_17  Row_82_Col_18  Row_82_Col_19   \n",
       "\n",
       "          aft_pauses  aft_causation    aft_falsity   aft_conflict  \n",
       "163     Row_1_Col_20   Row_1_Col_21   Row_1_Col_22   Row_1_Col_23  \n",
       "210     Row_2_Col_20   Row_2_Col_21   Row_2_Col_22   Row_2_Col_23  \n",
       "237     Row_3_Col_20   Row_3_Col_21   Row_3_Col_22   Row_3_Col_23  \n",
       "720     Row_4_Col_20   Row_4_Col_21   Row_4_Col_22   Row_4_Col_23  \n",
       "851     Row_5_Col_20   Row_5_Col_21   Row_5_Col_22   Row_5_Col_23  \n",
       "...              ...            ...            ...            ...  \n",
       "12094  Row_78_Col_20  Row_78_Col_21  Row_78_Col_22  Row_78_Col_23  \n",
       "12102  Row_79_Col_20  Row_79_Col_21  Row_79_Col_22  Row_79_Col_23  \n",
       "12317  Row_80_Col_20  Row_80_Col_21  Row_80_Col_22  Row_80_Col_23  \n",
       "12339  Row_81_Col_20  Row_81_Col_21  Row_81_Col_22  Row_81_Col_23  \n",
       "12533  Row_82_Col_20  Row_82_Col_21  Row_82_Col_22  Row_82_Col_23  \n",
       "\n",
       "[82 rows x 23 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_g.loc[163, 'pre_question'] = 'sd'\n",
    "df_g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Name, Text]\n",
       "Index: []"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for idx in indices:\n",
    "    start_idx = max(0, idx - 10)   \n",
    "    end_idx = min(len(df), idx + 11)   \n",
    "    sample = df.iloc[start_idx:end_idx][['Name', 'Text']].reset_index(drop=True)   \n",
    "    \n",
    "sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Yeah?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mia</td>\n",
       "      <td>Doesn't something about that seem odd to you?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Yeah, it does seem odd, now that you mention i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Manella</td>\n",
       "      <td>H-hmm? W-what do j00 mean? *sweats*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>When I went to that trailer, I saw something o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Manella</td>\n",
       "      <td>M-mmpf! No, er, ah, um, eh heh. Good call! *sw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>A t-bone steak, you mean?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Manella</td>\n",
       "      <td>Yeah, well, I mean the assistant went through ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>(Clearly a man who likes to eat. I'd suspected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Manella</td>\n",
       "      <td>We took one break during that meeting. I, er, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>(A mental image I will carry with me to my gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Manella</td>\n",
       "      <td>We were in the meeting until around 4:00...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>What were you discussing?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Manella</td>\n",
       "      <td>The Steel Samurai story, and our budget. Get t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>(Actually, I kind of can.) So, nobody left the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Manella</td>\n",
       "      <td>During the meeting, well, I'm pretty sure no o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Holdit.gif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>You didn't take a single break?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Manella</td>\n",
       "      <td>Er... well... Y-yeah! Not a one! *sweats*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>(Hmm... what's he sweating so much about, I wo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Phoenix</td>\n",
       "      <td>Wait a second! Mr. Manella, you've just contra...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Name                                               Text\n",
       "0   Phoenix                                              Yeah?\n",
       "1       Mia      Doesn't something about that seem odd to you?\n",
       "2   Phoenix  Yeah, it does seem odd, now that you mention i...\n",
       "3   Manella                H-hmm? W-what do j00 mean? *sweats*\n",
       "4   Phoenix  When I went to that trailer, I saw something o...\n",
       "5   Manella  M-mmpf! No, er, ah, um, eh heh. Good call! *sw...\n",
       "6   Phoenix                          A t-bone steak, you mean?\n",
       "7   Manella  Yeah, well, I mean the assistant went through ...\n",
       "8   Phoenix  (Clearly a man who likes to eat. I'd suspected...\n",
       "9   Manella  We took one break during that meeting. I, er, ...\n",
       "10  Phoenix  (A mental image I will carry with me to my gra...\n",
       "11  Manella        We were in the meeting until around 4:00...\n",
       "12  Phoenix                          What were you discussing?\n",
       "13  Manella  The Steel Samurai story, and our budget. Get t...\n",
       "14  Phoenix  (Actually, I kind of can.) So, nobody left the...\n",
       "15  Manella  During the meeting, well, I'm pretty sure no o...\n",
       "16  Phoenix                                         Holdit.gif\n",
       "17  Phoenix                    You didn't take a single break?\n",
       "18  Manella          Er... well... Y-yeah! Not a one! *sweats*\n",
       "19  Phoenix  (Hmm... what's he sweating so much about, I wo...\n",
       "20  Phoenix  Wait a second! Mr. Manella, you've just contra..."
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
