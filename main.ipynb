{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_tiwen(df, indexs): #提问，多类\n",
    "    question_words = [\"how\", \"what\", \"why\", \"where\", \"when\", \"who\", \"whom\", \"which\", \"whose\"]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(question_words) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return happen_list[0]\n",
    "    else:\n",
    "        return \"More\"\n",
    "\n",
    "def find_fanwen(df, indexs): #反问，3类\n",
    "    negatives_with_pronouns = [  \n",
    "    \"Wasn't it\",\"Aren't you\",\"Didn't you\",\"Wouldn't you\",\"Don't you\",\"Isn't that\",\"Isn't it\",\"Wasn't he\",\"Wasn't she\",\n",
    "    \"Wasn't they\",\"Weren't we\",\"Weren't you\",\"Haven't you\",\"Hasn't he\",\"Hasn't she\",\"Hadn't you\",\"Hadn't they\",\n",
    "    \"Wasn't there\",\"Wasn't here\",\n",
    "    \"Don't they\",\"Doesn't he\",\"Doesn't she\",\"Can't you\",\"Couldn't you\",\"Shouldn't you\",\"Wouldn't it\",\"Won't you\",\n",
    "    \"Needn't we\",\"Needn't they\",\"Mustn't you\",\"Daren't we\",\"Daren't they\",\"Was not it\",\"Are not you\",\"Did not you\",\n",
    "    \"Would not you\",\"Do not you\",\"Is not that\",\"Is not it\",\"Was not he\",\"Was not she\",\"Was not they\",\"Were not we\",\n",
    "    \"Were not you\",\"Have not you\",\"Has not he\",\"Has not she\",\"Had not you\",\"Had not they\",\"Do not they\",\"Does not he\",\n",
    "    \"Does not she\",\"Can not you\",\"Could not you\",\"Should not you\",\"Would not it\",\"Will not you\",\"Need not we\",\n",
    "    \"Need not they\",\"Must not you\",\"Dare not we\",\"Dare not they\"\"You sure\",\"You are sure\",\"You're sure\",\"Sure about that\",\n",
    "    \"Are you certain\",\"You certain\",\"Do you really think so\",\"You really think that\",\"Are you sure\",\n",
    "    \"You positive\",\"You sure about that\",\"Confident about that\",\"Are you convinced\",\"You convinced\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            for word in negatives_with_pronouns:\n",
    "                text = str(df.Text[i])\n",
    "                pattern_start = rf'\\b{re.escape(word)}\\b(?![^(]*\\))'\n",
    "                if re.findall(pattern_start, text, re.IGNORECASE):\n",
    "                    happen_list.extend([word])\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_gif(df, indexs): #gif，2类\n",
    "    happen_list = []\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b\\w+\\.gif\\b(?![^(]*\\))', text)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return 'Exist'\n",
    "    \n",
    "def find_thoughts(df, indexs): #心理，2类\n",
    "    happen_list = []\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\([^()]*\\)', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if bool(happen_list):\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return 'Null'\n",
    "\n",
    "def find_yinwen(df, indexs): # 引问，3类\n",
    "    positives_with_pronouns = [ \n",
    "    \"Was it\", \"Are you\", \"Did you\", \"Would you\",\"Do you\", \"Is that\", \"Is it\", \"Was he\", \"Was she\",\n",
    "    \"Were they\", \"Were we\", \"Were you\", \"Have you\",\"Has he\", \"Has she\", \"Had you\", \"Had they\",\n",
    "    \"Do they\", \"Does he\", \"Does she\", \"Can you\",\"Could you\", \"Should you\", \"Would it\", \"Will you\",\n",
    "    \"Need we\", \"Need they\", \"Must you\", \"Dare we\",\"Dare they\",\"whenever\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(positives_with_pronouns) + r')\\b(?![^(]*\\))', text , re.IGNORECASE)\n",
    "            happen_list = happen_list + word + re.findall(r\"correct[.!?]\", text, re.IGNORECASE)\n",
    "            \n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "\n",
    "def find_zhiyi(df, indexs): #质疑，3类\n",
    "    questioning_terms = [ \n",
    "    \"confused\", \"strange\", \"vague\", \"ridiculous\",\n",
    "    \"odd\", \"demand an explanation\", \"problem\", \"trap\",\n",
    "    \"blind spots\", \"useless\", \"unaware\", \"yet\", \"stinks\"\n",
    "    \"doubt\", \"challenge\", \"question\", \"query\",\n",
    "    \"dispute\", \"skeptical\", \"raise concerns\", \"ask\",\n",
    "    \"interrogate\", \"probe\", \"examine\", \"doubtful\",\n",
    "    \"call into question\", \"contest\", \"reconsider\", \"scrutinize\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(questioning_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_xujia(df, indexs): #虚假，2类\n",
    "    false_terms = [ \n",
    "    \"false\", \"fake\", \"fictitious\", \"bogus\", \"fraudulent\",\n",
    "    \"spurious\", \"counterfeit\", \"phony\", \"sham\", \"artificial\",\n",
    "    \"unreal\", \"impostor\", \"fabricated\", \"deceptive\", \"illusory\",\n",
    "    \"pretend\", \"pseudo\",\"fabrication\", \"lie\", \"lying \",\"unlikely\",\n",
    "    \"no way\",\"impossible\", \"wrong\", \"none\", \"no\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            word = re.findall(r'\\b(' + '|'.join(false_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "\n",
    "def find_fouding(df, indexs): #否定，2类\n",
    "    negatives = [ \n",
    "    \"am not\", \"is not\", \"isn't\", \"are not\", \"aren't\", \"was not\", \"wasn't\", \"were not\", \"weren't\",\n",
    "    \"have not\", \"haven't\", \"has not\", \"hasn't\", \"had not\", \"hadn't\",\n",
    "    \"do not\", \"don't\", \"does not\", \"doesn't\", \"did not\", \"didn't\",\n",
    "    \"will not\", \"won't\", \"would not\", \"wouldn't\", \"shall not\", \"shan't\", \n",
    "    \"should not\", \"shouldn't\", \"can not\", \"cannot\", \"can't\", \"could not\", \"couldn't\", \n",
    "    \"may not\", \"might not\", \"mightn't\", \"must not\", \"mustn't\", \"ought not to\", \"oughtn't to\",\n",
    "    \"need not\", \"needn't\", \"dare not\", \"daren't\", \"holding out against\",\n",
    "    'objection', \"oppose\", \"disagree\", \"object\",\"resist\", \"protest\",  \"contest\",\"Hold it right\",\"disagreement\"\n",
    "    \"refute\", \"counter\", \"dispute\", \"debate\",\"object to\",  \"take issue with\", \"hold out against\",\n",
    "    \"opposed\", \"disagreed\", \"objected\", \"resisted\", \"protested\", \"contested\",\n",
    "    \"refuted\", \"countered\", \"disputed\", \"debated\", \"objected to\", \"took issue with\",\n",
    "    \"held out against\",\"opposing\", \"disagreeing\", \"objecting\", \"resisting\", \"protesting\", \"contesting\",\n",
    "    \"refuting\", \"countering\", \"disputing\", \"debating\", \"objecting to\", \"taking issue with\"\n",
    "    ]\n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            for word in negatives:\n",
    "                text = str(df.Text[i])\n",
    "                pattern_middle = rf'\\b{re.escape(word)}\\b(?![^(]*\\))'\n",
    "                if re.findall(pattern_middle, text):\n",
    "                    happen_list.extend([word])\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    elif len(happen_list) == 1:\n",
    "        return 'Exist'\n",
    "    else:\n",
    "        return \"More\"\n",
    "    \n",
    "def find_yinguo(df, indexs): #因果，2类\n",
    "    causality = ['because','becaused','reason','so','reasons' ] \n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(causality) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "    \n",
    "def find_tingdun(df, indexs): #停顿，2类\n",
    "    pause = ['wait','moment','second','minute',\"moments\", \"seconds\", \"minutes\",\n",
    "            \"waited\", \"waited\", \"waiting\",\"Hold on\"] \n",
    "    happen_list = []\n",
    "    \n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(pause) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "    \n",
    "def find_judge(df): # judge\n",
    "    happen_list = []\n",
    "    for i in df.index:\n",
    "        if df.Name[i] == 'Judge':\n",
    "            return 'Exist'\n",
    "    return 'Null'\n",
    "\n",
    "def find_maodun(df, indexs): #矛盾，2类\n",
    "    contr_terms=['contradict', 'contradiction', 'conflict', 'confliction',\"contradicted\", \n",
    "                \"contradicted\", \"contradicting\", \"conflicted\", \"conflicted\", \"conflicting\", \n",
    "                \"contradictions\", \"conflicts\", \"conflictions\"] \n",
    "    happen_list = []\n",
    "\n",
    "    for i in indexs:\n",
    "        if df.Name[i] == 'Phoenix':\n",
    "            # 构建正则表达式模式以匹配 question_words 列表中的任何一个单词\n",
    "            text = str(df.Text[i])\n",
    "            word = re.findall(r'\\b(' + '|'.join(contr_terms) + r')\\b(?![^(]*\\))', text, re.IGNORECASE)\n",
    "            happen_list = happen_list + word\n",
    "\n",
    "    if len(happen_list) == 0:\n",
    "        return 'Null'\n",
    "    else:\n",
    "        return \"Exist\"\n",
    "\n",
    "def find_all(sample): # 函数总调用\n",
    "    middle_index = sample[(sample['Name'] == 'Phoenix') & (sample['Text'] == 'Objection.gif')].index\n",
    "    middle = middle_index.tolist()[0]\n",
    "    end = sample.index[-1]\n",
    "    temp = []\n",
    "    func_pre = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    func_aft = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    \n",
    "    result = [find_judge(sample)]\n",
    "    for func in func_pre:\n",
    "        result.append(func(sample, range(middle)))\n",
    "    for func in func_aft:\n",
    "        result.append(func(sample, range(middle+1, end+1)))\n",
    "    return result\n",
    "\n",
    "def select_numbers(data, num_to_select, min_gap): #随机采样负样本\n",
    "    selected = []\n",
    "    current_number = random.choice(data)\n",
    "    selected.append(current_number)\n",
    "    remaining_data = set(data) - {current_number}\n",
    "    while len(selected) < num_to_select:\n",
    "        valid_candidates = [num for num in remaining_data if abs(num - current_number) > min_gap]\n",
    "        if not valid_candidates:\n",
    "            raise ValueError(\"无法找到符合条件的更多数字\")\n",
    "        current_number = random.choice(valid_candidates)\n",
    "        selected.append(current_number)\n",
    "        remaining_data.remove(current_number)\n",
    "    return selected\n",
    "\n",
    "def e_find_all(e_sample): # 函数总调用（负样本）\n",
    "    middle = len(e_sample)//2\n",
    "    end = e_sample.index[-1]\n",
    "    temp = []\n",
    "    func_pre = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    func_aft = [find_tiwen, find_fanwen, find_gif, \n",
    "                find_thoughts, find_yinwen, find_zhiyi, \n",
    "                find_fouding, find_tingdun, find_yinguo,\n",
    "                find_xujia, find_maodun,]\n",
    "    \n",
    "    result = [find_judge(e_sample)]\n",
    "    for func in func_pre:\n",
    "        result.append(func(e_sample, range(middle)))\n",
    "    for func in func_aft:\n",
    "        result.append(func(e_sample, range(middle+1, end+1)))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:\\\\Users\\\\11326\\\\Desktop\\\\rule_leaning_new\\\\rule_learning\\\\rule_learning\\\\data.csv')\n",
    "indices = df[(df['Name'] == 'Phoenix') & (df['Text'] == 'Objection.gif')].index\n",
    "columns = [  #22个特征\n",
    "    'judge',\n",
    "    'pre_question', 'pre_rhetorical_question', 'pre_gif',\n",
    "    'pre_thoughts', 'pre_assess', 'pre_doubt',\n",
    "    'pre_negation', 'pre_pauses', 'pre_causation',\n",
    "    'pre_falsity', 'pre_conflict',\n",
    "    'aft_question', 'aft_rhetorical_question', 'aft_gif',\n",
    "    'aft_thoughts', 'aft_assess', 'aft_doubt',\n",
    "    'aft_negation', 'aft_pauses', 'aft_causation', \n",
    "    'aft_falsity', 'aft_conflict'\n",
    "]\n",
    "row_num = len(indices)  #行数\n",
    "col_num = len(columns)  #列数\n",
    "data = [[f'Row_{i+1}_Col_{j+1}' for j in range(col_num)] for i in range(row_num )] #初始值\n",
    "df_g = pd.DataFrame(data, columns=columns, index=indices) #生成数据表\n",
    "\n",
    "exist_idx = set()\n",
    "for idx in indices:\n",
    "    start_idx = max(0, idx - 10)  # 确保开始索引不小于0\n",
    "    end_idx = min(len(df), idx + 11)  # 确保结束索引不超过 DataFrame 长度\n",
    "    exist_idx.update(range(start_idx, end_idx))\n",
    "    adjacent_rows = df.iloc[start_idx:end_idx][['Name', 'Text']]  # 只选择 Name 和 Text 两列\n",
    "    sample = adjacent_rows.reset_index(drop=True) # 索引重新从0开始\n",
    "    df_g.loc[idx] = find_all(sample) #数据框赋值\n",
    "\n",
    "df_g['class'] = 'p'\n",
    "\n",
    "index_Phoenix = df[(df['Name'] == 'Phoenix')].index\n",
    "no_idx = []\n",
    "for i in index_Phoenix:\n",
    "    if i not in exist_idx and min(len(df), i+11) not in exist_idx and max(0, i-10) not in exist_idx:\n",
    "        no_idx.append(i)\n",
    "no_idx = no_idx[10:-10]  #剔除边界值\n",
    "\n",
    "min_gap = 50\n",
    "num = 82\n",
    "selected_index = select_numbers(no_idx, num, min_gap)\n",
    "\n",
    "for e_idx in selected_index:\n",
    "    e_adjacent_rows = df.iloc[e_idx-10 : e_idx+11][['Name', 'Text']]  # 只选择 Name 和 Text 两列\n",
    "    e_sample = e_adjacent_rows.reset_index(drop=True) # 索引重新从0开始\n",
    "    new_feature = e_find_all(e_sample) \n",
    "    new_feature.append('e')\n",
    "    df_g.loc[e_idx] = pd.Series(new_feature, index=df_g.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[judge=Exist ^ pre_gif=Exist] V\n",
      "[aft_gif=Exist] V\n",
      "[judge=Exist ^ aft_doubt=Exist] V\n",
      "[pre_pauses=Exist] V\n",
      "[pre_question=where]]\n",
      "accuracy: 0.7454545454545455\n",
      "precision: 0.75\n",
      "recall: 0.75\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[645,\n",
       " 1340,\n",
       " 2325,\n",
       " 5163,\n",
       " 5767,\n",
       " 6624,\n",
       " 6662,\n",
       " 6750,\n",
       " 8659,\n",
       " 9773,\n",
       " 10178,\n",
       " 11090,\n",
       " 11502,\n",
       " 12059]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import wittgenstein as lw\n",
    "train, test = train_test_split(df_g, test_size=.33, random_state=42)\n",
    "clf = lw.RIPPER()\n",
    "clf.fit(train, class_feat='class', pos_class='p')\n",
    "clf.out_model()\n",
    "X_test = test.drop('class', axis=1)\n",
    "y_test = test['class']\n",
    "\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "from sklearn.metrics import precision_score,recall_score,accuracy_score\n",
    "accuracy = clf.score(X_test, y_test)\n",
    "precision = clf.score(X_test, y_test, precision_score)\n",
    "recall = clf.score(X_test, y_test, recall_score)\n",
    "print(f'accuracy: {accuracy}')\n",
    "print(f'precision: {precision}')\n",
    "print(f'recall: {recall}')\n",
    "bool_list = clf.predict(X_test)\n",
    "converted_list = ['p' if x else 'e' for x in bool_list]\n",
    "test_save = test.copy()\n",
    "test_save['predict'] = converted_list \n",
    "condition = test_save['class'] != test_save['predict']\n",
    "different_indices = test_save.index[condition]\n",
    "different_indices_list = different_indices.tolist()\n",
    "sorted(different_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2223, 5676, 5686, 6750, 11090, 11502, 12261, 12269, 12407]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bool_list = clf.predict(X_test)\n",
    "converted_list = ['p' if x else 'e' for x in bool_list]\n",
    "test_save = test.copy()\n",
    "test_save['predict'] = converted_list \n",
    "condition = test_save['class'] != test_save['predict']\n",
    "different_indices = test_save.index[condition]\n",
    "different_indices_list = different_indices.tolist()\n",
    "sorted(different_indices_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[judge=Exist ^ aft_thoughts=Null ^ aft_assess=Exist] V\n",
      "[judge=Exist ^ aft_thoughts=Null ^ aft_causation=Null ^ pre_gif=Exist] V\n",
      "[judge=Exist ^ aft_gif=Exist] V\n",
      "[judge=Exist ^ aft_doubt=Exist] V\n",
      "[pre_rhetorical_question=Exist] V\n",
      "[pre_negation=Exist ^ judge=Exist]]\n"
     ]
    }
   ],
   "source": [
    "list = clf.out_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1 = [1312, 5676, 5686, 6750, 11090, 12261, 12269, 12407]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "for index in list_1:\n",
    "    rows = df.iloc[index-10 : index+11][['Name', 'Text']] \n",
    "    file_name = f'different_{index}.csv'\n",
    "    rows.to_csv(file_name, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practice",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
